{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b80469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82cfff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d697b373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d3cefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Yudi Dataframe\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45809f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Yudi Dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1970e587f10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35ba56d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'D:\\python\\meTryPython\\learnspark\\first\\resources\\test1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20610d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|Age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sundhansh| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 21|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.option('header','true').csv(filepath,inferSchema=True)\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f129c90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "571c8cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|Age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sundhansh| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 21|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark=spark.read.csv(filepath,header=True,inferSchema=True)\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69490cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fd03526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0778dbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Experience', 'Salary']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "624b33ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|Age|\n",
      "+---+\n",
      "| 31|\n",
      "| 30|\n",
      "| 29|\n",
      "| 24|\n",
      "| 21|\n",
      "| 21|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('Age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b21e41ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|     Name|Experience|\n",
      "+---------+----------+\n",
      "|    Krish|        10|\n",
      "|Sundhansh|         8|\n",
      "|    Sunny|         4|\n",
      "|     Paul|         3|\n",
      "|   Harsha|         1|\n",
      "|  Shubham|         2|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select(['Name','Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33b33a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|     Name| exp_name|\n",
      "+---------+---------+\n",
      "|    Krish|   Senior|\n",
      "|Sundhansh|   Senior|\n",
      "|    Sunny|Associate|\n",
      "|     Paul|Associate|\n",
      "|   Harsha|   Junior|\n",
      "|  Shubham|   Junior|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select(\"Name\",when(df_spark['Experience'] >=5,\"Senior\")\n",
    "                .when((df_spark['Experience'] <=5) & (df_spark['Experience']  >2),\"Associate\")\\\n",
    "                .otherwise(\"Junior\")\n",
    "                .alias(\" exp_name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be7a062b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|     Name| exp_name|\n",
      "+---------+---------+\n",
      "|    Krish|   Senior|\n",
      "|Sundhansh|   Senior|\n",
      "|    Sunny|Associate|\n",
      "|     Paul|Associate|\n",
      "|   Harsha|   Junior|\n",
      "|  Shubham|   Junior|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select(\"Name\", \n",
    "                when(df_spark.Experience >= 5, \"Senior\")\n",
    "                .when((df_spark.Experience <= 5) & (df_spark.Experience > 2), \"Associate\")\n",
    "                .otherwise(\"Junior\")\n",
    "                .alias(\" exp_name\"),\n",
    "                ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58535e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Name: string, Age: string, Experience: string, Salary: string]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d807cfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77f296db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|Age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sundhansh| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 21|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29880084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5573509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+-----------+-----------+\n",
      "|      mean_column1|   stddev_column1|min_column1|max_column1|\n",
      "+------------------+-----------------+-----------+-----------+\n",
      "|21333.333333333332|5354.126134736337|      15000|      30000|\n",
      "+------------------+-----------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agg_df_spark = df_spark.agg(\n",
    "    F.mean(\"Salary\").alias(\"mean_column1\"),\n",
    "    F.stddev(\"Salary\").alias(\"stddev_column1\"),\n",
    "    F.min(\"Salary\").alias(\"min_column1\"),\n",
    "    F.max(\"Salary\").alias(\"max_column1\"))\n",
    "\n",
    "agg_df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfdb4e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+------------------------+\n",
      "|     Name|Age|Experience|Salary|Experience After 2 years|\n",
      "+---------+---+----------+------+------------------------+\n",
      "|    Krish| 31|        10| 30000|                      12|\n",
      "|Sundhansh| 30|         8| 25000|                      10|\n",
      "|    Sunny| 29|         4| 20000|                       6|\n",
      "|     Paul| 24|         3| 20000|                       5|\n",
      "|   Harsha| 21|         1| 15000|                       3|\n",
      "|  Shubham| 21|         2| 18000|                       4|\n",
      "+---------+---+----------+------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_2year = df_spark.withColumn('Experience After 2 years',\n",
    "                               df_spark['Experience']+2)\n",
    "df_spark_2year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37de8262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "| New Name|Age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sundhansh| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 21|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n",
      "+---------+---+----------+------+\n",
      "|     Name|Age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sundhansh| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 21|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_newName = df_spark.withColumnRenamed('Name','New Name')\n",
    "df_spark_newName.show()\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3823cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# new_row = Row(Name='Sundhansh', Age=45, Experience=20, Salary= 55000)\n",
    "# new_row['Sundhansh',45,20,55000]\n",
    "# new_df = spark.createDataFrame([new_row], schema=df_spark.schema)\n",
    "df_spark2 = df_spark.union(spark.createDataFrame([new_row]).toDF('Name', 'Age', 'Experience', 'Salary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0a278db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_spark2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d6ac0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error on calling method show() to appended dataframe from 2 cell above\n",
    "# df_spark2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7d175b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+--------+---------------+-----------+\n",
      "| New Name|Salary|max(Age)|max(Experience)|max(Salary)|\n",
      "+---------+------+--------+---------------+-----------+\n",
      "|Sundhansh| 25000|      30|              8|      25000|\n",
      "|     Paul| 20000|      24|              3|      20000|\n",
      "|    Sunny| 20000|      29|              4|      20000|\n",
      "|   Harsha| 15000|      21|              1|      15000|\n",
      "|    Krish| 30000|      31|             10|      30000|\n",
      "|  Shubham| 18000|      21|              2|      18000|\n",
      "+---------+------+--------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_newName.groupBy(\"New Name\", \n",
    "                         \"Salary\",\n",
    "                        ).max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc0db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1069882a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
